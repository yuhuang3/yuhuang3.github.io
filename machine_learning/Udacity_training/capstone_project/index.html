<h1> Predicting Hospitalized Time of Covid-19 Patients</h1>
<h2> Supervised Machine Learning in Healthcare </h2>
<div>
    <img src="./images/scene.jpg" width="50%" alt="Yu"> 
</div>
<h3> Yu Huang </h3>

<h2> 1. Intruduction </h2>
<p>
The outbreak of Covid-19 pandemic in 2020 caused tremendous equipment, materials deficiency and beds shortage problems in healthcare system across the U.S. [1]. The hospitals not only need to take care of the routine patients, but also need to take care of the sudden increased Covid-19 patients. A good planning and management of a hospital system becomes very important.
This article presents how new methods to use machine-learning to predict how long (in days) a Covid-19 patient needs to stay in a hospital at the time of admission. This can help hospital professionals to make an optimized planning for patient treatment and resources (e.g., room, bed, etc.) allocation. This also could reduce the amount of hospital visitors and so decrease the chance of staff and visitor infection.
The rest of this article is arranged as follows:
</p>
<ul>
    <li>Data understanding</li>
    <li>Data preparation</li>
    <li>Modeling</li>
    <li>Model evaluation</li>
    <li>Deployment </li>
</ul>


<h2> 1. Data Understanding </h2>

The dataset is obtained from Kaggle's website [1]. There are three files used in this article:
train_data.csv: containing features related to patient, hospital and Length of stay (label)
test_data.csv: containing features related to patient, hospital. Need to predict the "length" of stay for each case id
train_data_dictionary.csv: containing the information of the features in train and test files.

As shown in Figure 1, there are total 17 features and 1 label column (Stay) in this dataset.

<br>
<img src="./images/covid19_data_transposed_view.png" width="70%" alt="top 10 languages in 2017">
<br>
<center> Figure 1: Transposed view of the train dataset. </center>
<br>
<p>
    Figure 2 shows the distribution of the following numeric features:
<ul>
    <li>case_id</li>
    <li>Hospital_code</li>
    <li>City_Code_Hospital</li>
    <li>Available Extra Rooms in Hospital</li>
    <li>Bed Grade</li>
    <li>patientid</li>
    <li>City_Code_Patient</li>
    <li>Visitors with Patient</li>
    <li>Admission_Deposit</li>
 </ul>   
    It can be seen that the case_id feature values are uniformly distributed 
    over bins because they are unique sequential numbers. 
    This feature can be dropped due to lack of prediction power.    
</p>

<br>
<img src="./images/numeric_features_distribution.png" width="50%" alt="top 10 languages in 2017">
<br>
<center> Figure 2: Distribution of numeric features. </center>
<br>

<p>
    Figure 3 shows the patient visit distribution. 
    We can see that many patients revisited the hospital many times 
    (from 10 up to 50). So patient IDs are important in prediction.
</p>

<br>
<img src="./images/patient_visits_distribution.png" width="40%" alt="top 10 languages in 2017">
<br>
<center> Figure 3: Patient visit distribution. </center>
<br>

<p>
    Figure 4 shows the distribution of the categorical features and label column:
<ul>
    <li>Hospital type code</li>
    <li>Hospital region code</li>
    <li>Department</li>
    <li>Ward Type</li>
    <li>Ward Facility Code</li>
    <li>Type of Admission</li>
    <li>Severity of Illness</li>
    <li>Age</li>
    <li>Stay (Label)</li>
</ul>

We can see that the distribution of the labels is significantly skewed to 
the right. In other words, the data is not balanced. 
There are very few data samples in the categories from '41–50' to '61–70'. 
This will have significant negative impact on prediction power.
</p>

<br>
<img src="./images/categorical_features_distribution.png" width="50%" alt="top 10 languages in 2017">
<br>
<center> Figure 4: Distribution of categorical features. </center>
<br>

<h2> 2. Data preparation </h2>

With data understanding, The next step is to explore, 
clean and transform the collected raw dataset into appropriate format 
so that the transformed data can be effectively consumed by a target machine learning model.

<h3>2.1. Handling missing data</h3>

As shown in Figure 5, there are 113 missing data in the Bed Grade feature column 
and 4,532 missing data in the City_Code_Patient feature column. 
The total number of missing data is relatively small (total of 4,645) 
compared with the dataset size of 318,438 rows. 
In this case we can either drop the rows with missing data or replace missing data with 0. 
I choose to replace the missing data with 0 in order to be able to predict results 
for the test_data dataset with missing feature values in deployment. 
Refer to the DataCleaning class in data_preprocessing.py for details [6].

<p>
train_data.isnull().sum()
</p>

<br>
<img src="./images/missing_data_count.png" width="30%" alt="top 10 languages in 2017">
<br>
<center> Figure 5: Count of missing data. </center>
<br>

<h3>2.2 Dropping features (columns) without prediction power</h3>
As described before, the case_id feature doesn't have prediction power, 
so it is dropped in this project (see the DataCleaning class in data_preprocessing.py[6]).

<h3>2.3 Categorical Encoding</h3>
<h4>2.3.1. Categorical label encoding</h4>
The label column Stay in this dataset is categorical. It must be transformed into numbers for categorical feature target encoding [7] and deep learning model. The LabelEncoder algorithm [8] is used for the transformation (see TargetEncoding and OneHotEncoding classes in data_preprocessing.py[6]).
<h4>2.3.2 Categorical feature target encoding</h4>
The advantage of target encoding [7] is that it does not increase the dimensionality of the dataset. It has been used in this project for transforming categorical features into numbers for ensemble machine learning models XGBoost [2] and Random Forest [3] because these models don't work well with one-hot encoding due to high dimensionality. See the TargetEncoding class in data_preprocessing.py[6].
<h4>2.3.3. Categorical feature one-hot encoding</h4>
For comparison, the popular one-hot encoding method is used for transforming categorical features as well for deep learning model (see the OneHotEncoding class in data_preprocessing.py[6]).
<h4>2.3.4. Other categorical feature transformation</h4>
I noticed that the categorical Age feature (e.g. "21–30") has more prediction power once it is transformed into numbers because the order of ages makes difference. In this project each range of age (e.g., "21–30") has been transformed into an average number like (21+30)/2 = 25.5 (see the OneHotEncoding class in data_preprocessing.py[6]).
<h3>2.4. Feature Normalization</h3>
The numeric features are normalized into the range of [-1, 1] for deep learning (see the FeatureNormorlization class in data_preprocessing.py[6]).
<h3>2.5. Data Splitting</h3>
Finally, the preprocessed dataset is divided into two subsets: one for model training and the other for model evaluation.
<h3>2.6. Data Preprocessing Pipelines</h3>
The data preparation steps 2.1–2.5 have been combined into data preprocessing pipelines for convenience:
<ul>
    <li>target_encoding_preprocessing</li>
    <li>target_encoding_preprocessing_for_prediction</li>
    <li>onehot_encoding_preprocessing</li>
    <li>onehot_encoding_preprocessing_for_prediction</li>
</ul>
<br>

See data_preprocessing.py for details [6].


<h2> 3. Modeling </h2>

After data preparation, we are ready for modeling. The main goals of modeling include:
<ul>
    <li>Identify potential machine learning models</li>
    <li>Train models and tune the hyper-parameters of models</li>
</ul>

<h3>3.1. Model Selection</h3>
This project addresses a classification issue because the label is categorical. 
This is suitable for supervised machine learning classification models such as XGBoost [2], 
Random Forest [3], deep learning multilayer perceptron (MLP) classifiers [4].
Because the data is in tabular format and the number of features is relatively small, 
XGBoost and Random Forest are generally preferred compared with deep learning models.
In this project XGBoost, Random Forest, and MLP classifiers are selected for experiments.

<h3>3.2. Model Training and Hyper-Parameters Tuning</h3>

Both XGBoost and Random Forest model training are performed with 10 folder cross validation. 
Grid search is used for selecting the best combination of hyper-parameters. 
Cross validation is also used for training the deep learning model. 
See the following functions in train_test_classifier.py:

<ul>
    <li>build_xgboost_model</li>
    <li>build_rf_model</li>
    <li>build_deeplearning_model</li>
</ul>

<h2> 4. Model evaluation </h2>

Once different machine learning models have been trained, the performance of these models needs to be evaluated so that we can select the best model for deployment. 
The classification accuracy and confusion matrix are used as the main evaluation metrics for this project. Refer to the following functions in train_test_classifier.py for details:
<ul>
    <li>evaluate_xgboost_model</li>
    <li>evaluate_rf_model</li>
    <li>evaluate_dl_model</li>
</ul>

<h3>4.1. MLflow</h3>
In order to effectively tracking model hyper-parameters and performance metrics, the MLflow tool [5] is used. In particular, I developed the function mlFlow() in train_test_classifier.py to combine the following activities into one procedure:
<ul>
    <li>Loading training data</li>
    <li>Preprocessing data</li>
    <li>Training model</li>
    <li>Evaluating model</li>
</ul>

As an example, the following mlFlow() function call produces the results 
(e.g., the confusion matrix in Figure 6) for a XGBoost model.

<p>
    target_encoders, label_encoder = mlFlow()
</p>

<br>
<img src="./images/xgboost_confusion_matrix.png" width="70%" alt="top 10 languages in 2017">
<br>
<center> Figure 6: Confusion Matrix for a XGBoost model.</center>
<br>
The confusion matrix in Figure 6 shows that the more data the better the prediction results. 
For example, the maximum number 14,429 of true positives is in the category of 21–30.

Figure 7 shows the results of four model evaluations:
<ul>
    <li>XGBoost with target encoding</li>
    <li>Random Forest with target encoding</li>
    <li>MLP with target encoding</li>
    <li>MLP with one-hot encoding</li>
</ul>

We can see that XGBoost has the best performance in accuracy for the given dataset and 
so we can select it for deployment if its performance meets business requirements.

<br>
<img src="./images/mlflow.png" width="70%" alt="top 10 languages in 2017">
<br>
<center> Figure 7: MLflow UI screenshot.</center>
<br>
As shown in Figure 7, the best accuracy score is only about 42.4%. 
This is because there are too little data in the majority of the labeled categories 
such as the following ranges: 41-50, from 61-70 all way up to more than 100.
<br><br>
The accuracy score will increase if more data can be collected to balance the dataset. 
As an experiment, I selected only the data samples in the categories of 11-20 and 21-30 and 
noticed that the accuracy score was increased to about 63%. 
Figure 8 shows the corresponding confusion matrix from a trained Random Forest model.

<br>
<img src="./images/rf_filtered_confusion_matrix.png" width="40%" alt="">
<br>
<center> Figure 8: Confusion Matrix for a Random Forest model with two label categories.</center>
<br>
In order to understand how different features impacted the prediction, 
Figure 9 shows the feature importance produced by a trained Random Forest model.

<br>
<img src="./images/features_importance.png" width="50%" alt="">
<br>
<center> Figure 9: Feature importance produced by a Random Forest model.</center>
<br>

I also looked into the correlations between the features and the target labels 
as shown in Figure 10.

<br>
<img src="./images/correlation_analysis.png" width="30%" alt="">
<br>
<center> Figure 10: Features and target label (Stay) correlation coefficients.</center>
<br>

It is tricky to use correlation coefficient to determine the strength of relationship 
between a feature and the target because the correlation coefficient only indicates 
linear relationship. A feature (e.g., patientid) with very low correlation coefficient 
does not necessary indicate that there is no relationship between the feature and the target. 
For example, the patient id has a very small correlation coefficient, 
but its feature importance is high.
<br><br>
I tried to remove some of the features with low feature importance 
(e.g., Hospital_region_code, City_Code_Hospital, etc.) and features with very small 
correlation coefficients (e.g., City_Code_Hospital) and observed that it didn't help 
to increase accuracy score.

<h2> 5. Deployment </h2>

Once the best model has been identified for deployment in model evaluation, 
we can move to the final step to deploy the identified model into a production environment. 
One common deployment method is to deploy the model as a Web service on a server, 
which can be called by other components in a target production system to predict results.
<br><br>
In order to support deployment, both the selected trained model (e.g., XGBoost) and the 
related encoding objects (e.g., LabelEncoder object, TargetEncoder objects) are saved into 
Python pickle files after model training. These saved encoding objects and model are to 
be loaded back for prediction in deployment.
<br><br>
As an example, the following code loads in thetest_data.csv for prediction in deployment. 
Figure 11 shows the transposed view of the loaded test dataset. Note that this dataset 
does not have the label column Stay.

<p>
    test_data = load_data('test_data.csv') <br>
    print(test_data.shape)<br>
    test_data.transpose().head(100)
</p>

<br>
<img src="./images/test_data.png" width="30%" alt="">
<br>
<center> Figure 11: Test data before prediction.</center>
<br>

The code below does the following:
<ul>
    <li>loading the saved model and encoding objects</li>
    <li>using them to predict the number of hospitalized days for each of the patients 
        in the test dataset</li>
    <li>showing the first 100 records in the resulting DataFrame with the features and 
        predicted labels (the Stay column) (see Figure 12)</li>
    <li>displaying the distribution of the predicted labels.</li>
</ul>

We can see from Figure 4 and Figure 13 that the distribution pattern of the predicted labels 
in Figure 13 is very similar to the distribution pattern of the labels Figure 4.

<p>
label_encoder, target_encoders = load_encoders()<br>
result_df = predict(label_encoder, target_encoders, test_data_file='test_data.csv')<br>
result_df['Stay'].value_counts().plot(kind='bar')<br>
result_df.transpose().head(100)
</p>

<br>
<img src="./images/prediction_results.png" width="70%" alt="">
<br>
<center> Figure 12: Test data with predicted labels.</center>
<br>
<br><br>
<br>
<img src="./images/predicted_labels_distribution.png" width="30%" alt="">
<br>
<center> Figure 13: Distribution of predicted labels.</center>
<br>

<h2> Summary </h2>
This article presented how to use different machine learning models to predict the hospitalized 
time for Covid-19 patients using a challenging dataset from Kaggle [1]. 
This dataset is difficult in that it is a multi-classes single label case and the dataset is 
significantly skewed.
<br><br>
The experimental results show that using XGBoost with target encoding achieved the best performance 
in prediction accuracy (42.4%). This result is competitive to the results described in Kaggle [1].

<h2> References </h2>
<ol>
    <li><a href="https://www.kaggle.com/nehaprabhavalkar/av-healthcare-analytics-ii">Covid-19 dataset in Kaggle</a></li>
    <li><a href="https://xgboost.readthedocs.io/en/latest/">XGBoost</a></li>
    <li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">Random Forest Classifier</a></li>
    <li><a href="https://keras.io/guides/sequential_model/">Keras sequential model</a></li>
    <li><a href="https://mlflow.org/docs/latest/index.html">MLflow</a></li>
    <li><a href="https://github.com/yuhuang3/machine-learning/tree/master/Udacity/capstone_projec">Source code in Github</a></li>
    <li><a href="https://contrib.scikit-learn.org/category_encoders/targetencoder.html">Target encoder</a></li>
    <li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html">Label encoder</a></li>
</ol>


